Project Task: Week 1

Importing, Understanding, and Inspecting Data :

Perform preliminary data inspection and report the findings as the structure of the data, missing values, duplicates, etc.

Variable names in the data may not be in accordance with the identifier naming in Python so, change the variable names accordingly

The presented data might also contain some missing values therefore, exploration will also lead to devising strategies to fill in the missing values while exploring the data

Performing EDA:

Provide the statistical description of the quantitative data variables

Explain how is the target variable distributed overall

Study the distribution of the target variable across various categories like branch, city, state, branch, supplier, manufacturer, etc.

What are the different employment types given in the data? Can a strategy be developed to fill in the missing values (if any)?  Use pie charts to express the different types of employment that define the defaulters and non-defaulters.

Has age got anything to do with defaulting? What is the distribution of age w.r.t. to the defaulters and non-defaulters?

What type of ID was presented by most of the customers for proof?

 

Project Task: Week 2

Performing EDA and Modeling:

Study the credit bureau score distribution. Compare the distribution for defaulters vs. non-defaulters. Explore in detail.

Explore the primary and secondary account details. Is the information in some way related to the loan default probability?

Is there a difference between the sanctioned and disbursed amount of primary and secondary loans? Study the difference by providing appropriate statistics and graphs.

Do customer who make higher number of enquiries end up being higher risk candidates? 

Is credit history, that is new loans in last six months, loans defaulted in last six months, time since first loan, etc., a significant factor in estimating probability of loan defaulters?

Perform logistic regression modeling, predict the outcome for the test data, and validate the results using the confusion matrix.

Dashboarding:

Visualize the data using Tableau to help user explore data to have a better understanding

Demonstrate the variables associated with each other and factors to build a dashboard