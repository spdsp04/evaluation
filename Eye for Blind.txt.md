You have explored the data and extracted both images and captions separately . . . . . .

You have performed preprocessing on both captions and images. . . . . . . . . 

You have created train & test dataset using tf.data API with 80-20 ratio. . . . . .

You have extracted the features of each images using pretrained Imagenet weights of Inception net V3 . . . . . .

You have build build the models for Encoder, Attention model & decoder successfully to create the encoder - decoder architecture. 

You have set the optimizer & loss object for the model & created functions for both training & testing steps.  . . . . . .

You have defined the evaluation function clearly with the help of greedy search

You have tested on the sample dataset using BLEU score.

the code is decently readable and well-commented . . . . . . .    

appropriate libraries are used to make the code concise (rather than using long, verbose code)


